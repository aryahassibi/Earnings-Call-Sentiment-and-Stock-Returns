{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Sentiment Scoring Pipeline\n",
    "\n",
    "Implements the sentiment tool described in the project mail. We apply a transformer model (FinBERT by default) to each earnings call transcript and persist engineered sentiment features for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & configuration\n",
    "Tweak the file paths for the JupyterHub server vs. local runs. Use `SAMPLE_SIZE` to dry-run a handful of filings before scaling to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5fb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryahassibi/Desktop/School/Data and Ai in economics/jupy/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: Sentiment pipeline configured.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "TRANSCRIPTS_PATH = Path('data/transcripts.parquet')\n",
    "CACHE_DIR = Path('sent_cache')\n",
    "OUTPUT_DIR = Path('output')\n",
    "OUTPUT_FILE = OUTPUT_DIR / 'sentiment_features.parquet'\n",
    "\n",
    "TEXT_COLUMN = 'full_transcript'\n",
    "ID_COLUMNS = ['symbol', 'year', 'quarter']\n",
    "SAMPLE_SIZE: Optional[int] = 10  # set to None when ready for the full run\n",
    "BATCH_SIZE = 16\n",
    "MAX_TOKENS = 450\n",
    "MIN_TOKENS = 120\n",
    "OVERLAP_SENTS = 0\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "logging.info('Sentiment pipeline configured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d2299e",
   "metadata": {},
   "source": [
    "## Load transcripts\n",
    "We reuse the parquet file inspected in notebook 00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824512a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading transcripts from data/transcripts.parquet\n",
      "INFO: Loaded 10 transcripts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>full_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Operator: Good morning ladies and gentlemen an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>Operator: Good day, ladies and gentlemen, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>Operator: Good day, ladies and gentlemen, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>Operator: Good day, ladies and gentlemen, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>Operator: Good day, ladies and gentlemen, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  quarter                                    full_transcript\n",
       "0      A  2010        1  Operator: Good morning ladies and gentlemen an...\n",
       "1      A  2010        2  Operator: Good day, ladies and gentlemen, and ...\n",
       "2      A  2011        1  Operator: Good day, ladies and gentlemen, and ...\n",
       "3      A  2011        2  Operator: Good day, ladies and gentlemen, and ...\n",
       "4      A  2011        3  Operator: Good day, ladies and gentlemen, and ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not TRANSCRIPTS_PATH.exists():\n",
    "    raise FileNotFoundError(f'Transcripts file not found at {TRANSCRIPTS_PATH}. Update TRANSCRIPTS_PATH.')\n",
    "\n",
    "logging.info('Loading transcripts from %s', TRANSCRIPTS_PATH)\n",
    "try:\n",
    "    import pyarrow.parquet as pq\n",
    "    transcripts_df = pq.read_table(TRANSCRIPTS_PATH).to_pandas()\n",
    "except Exception as exc:\n",
    "    logging.warning('Falling back to pandas.read_parquet: %s', exc)\n",
    "    transcripts_df = pd.read_parquet(TRANSCRIPTS_PATH)\n",
    "\n",
    "if SAMPLE_SIZE is not None:\n",
    "    transcripts_df = transcripts_df.head(SAMPLE_SIZE)\n",
    "\n",
    "logging.info('Loaded %s transcripts', len(transcripts_df))\n",
    "transcripts_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d957f2b",
   "metadata": {},
   "source": [
    "## Sentence segmentation & chunking\n",
    "Split transcripts into sentences, then pack them into chunks that respect transformer token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a00694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "_NLP = spacy.blank('en')\n",
    "if 'sentencizer' not in _NLP.pipe_names:\n",
    "    _NLP.add_pipe('sentencizer')\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    doc = _NLP(' '.join(text.split()))\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def pack_sentences_to_token_chunks(\n",
    "    sentences: List[str],\n",
    "    tokenizer,\n",
    "    max_tokens: int = MAX_TOKENS,\n",
    "    min_tokens: int = MIN_TOKENS,\n",
    "    overlap_sents: int = OVERLAP_SENTS,\n",
    ") -> List[Dict]:\n",
    "    if not sentences:\n",
    "        return []\n",
    "    chunks, buf, buf_tokens = [], [], 0\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        sent = sentences[i]\n",
    "        t = len(tokenizer.tokenize(sent))\n",
    "        if buf and buf_tokens + t > max_tokens:\n",
    "            chunk_text = ' '.join(buf)\n",
    "            n_tokens = len(tokenizer.tokenize(chunk_text))\n",
    "            chunks.append({\n",
    "                'text': chunk_text,\n",
    "                'n_tokens': n_tokens,\n",
    "                'start_idx': i - len(buf),\n",
    "                'end_idx': i - 1,\n",
    "            })\n",
    "            if overlap_sents > 0:\n",
    "                overlap = buf[-overlap_sents:]\n",
    "                buf = overlap[:]\n",
    "                buf_tokens = len(tokenizer.tokenize(' '.join(buf)))\n",
    "            else:\n",
    "                buf, buf_tokens = [], 0\n",
    "            continue\n",
    "        buf.append(sent)\n",
    "        buf_tokens += t\n",
    "        i += 1\n",
    "    if buf:\n",
    "        chunk_text = ' '.join(buf)\n",
    "        n_tokens = len(tokenizer.tokenize(chunk_text))\n",
    "        if chunks and n_tokens < min_tokens:\n",
    "            prev = chunks.pop()\n",
    "            merged = prev['text'] + ' ' + chunk_text\n",
    "            chunks.append({\n",
    "                'text': merged,\n",
    "                'n_tokens': len(tokenizer.tokenize(merged)),\n",
    "                'start_idx': prev['start_idx'],\n",
    "                'end_idx': len(sentences) - 1,\n",
    "            })\n",
    "        else:\n",
    "            chunks.append({\n",
    "                'text': chunk_text,\n",
    "                'n_tokens': n_tokens,\n",
    "                'start_idx': len(sentences) - len(buf),\n",
    "                'end_idx': len(sentences) - 1,\n",
    "            })\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52898d5b",
   "metadata": {},
   "source": [
    "## Load FinBERT (or another Hugging Face classifier)\n",
    "The default is `ProsusAI/finbert`. Swap `MODEL_NAME` to explore alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffebf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'neutral']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'ProsusAI/finbert'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "LABEL_ORDER = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "LABEL_ORDER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d778a",
   "metadata": {},
   "source": [
    "## Batched scoring with caching\n",
    "Minimise repeated model calls by storing chunk-level outputs on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3832df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(cache_dir: Path = CACHE_DIR) -> Path:\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    return cache_dir\n",
    "\n",
    "def stable_hash(text: str) -> str:\n",
    "    return hashlib.blake2s(text.encode('utf-8'), digest_size=8).hexdigest()\n",
    "\n",
    "def maybe_read_cache(cache_dir: Path, key: str):\n",
    "    fp = cache_dir / f'{key}.json'\n",
    "    if fp.exists():\n",
    "        return json.loads(fp.read_text())\n",
    "    return None\n",
    "\n",
    "def write_cache(cache_dir: Path, key: str, payload):\n",
    "    (cache_dir / f'{key}.json').write_text(json.dumps(payload))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def score_chunks(\n",
    "    chunks: List[Dict],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    cache_dir: Path = CACHE_DIR,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    max_length: int = 512,\n",
    "    label_order: Iterable[str] = LABEL_ORDER,\n",
    ") -> List[Dict]:\n",
    "    cache_dir = load_cache(cache_dir)\n",
    "    results = []\n",
    "    batch_texts, batch_keys, pending = [], [], []\n",
    "\n",
    "    def flush():\n",
    "        if not batch_texts:\n",
    "            return\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        probs = F.softmax(logits, dim=-1).cpu().tolist()\n",
    "        formatted = [\n",
    "            [{\n",
    "                'label': label_order[j],\n",
    "                'score': row[j],\n",
    "            } for j in range(len(label_order))]\n",
    "            for row in probs\n",
    "        ]\n",
    "        for key, payload, meta in zip(batch_keys, formatted, pending):\n",
    "            write_cache(cache_dir, key, payload)\n",
    "            results.append({\n",
    "                'key': key,\n",
    "                'scores': payload,\n",
    "                'n_tokens': meta['n_tokens'],\n",
    "            })\n",
    "        batch_texts.clear()\n",
    "        batch_keys.clear()\n",
    "        pending.clear()\n",
    "\n",
    "    for ch in chunks:\n",
    "        key = stable_hash(ch['text'])\n",
    "        cached = maybe_read_cache(cache_dir, key)\n",
    "        if cached is not None:\n",
    "            results.append({\n",
    "                'key': key,\n",
    "                'scores': cached,\n",
    "                'n_tokens': ch['n_tokens'],\n",
    "            })\n",
    "            continue\n",
    "        batch_texts.append(ch['text'])\n",
    "        batch_keys.append(key)\n",
    "        pending.append(ch)\n",
    "        if len(batch_texts) >= batch_size:\n",
    "            flush()\n",
    "    flush()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8631f",
   "metadata": {},
   "source": [
    "## Aggregate chunk scores to transcript-level features\n",
    "Engineer interpretable metrics (weighted means, dispersion, extremes) to use in regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d135a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distlist_to_array(distlist: List[Dict], label_order: Iterable[str] = LABEL_ORDER):\n",
    "    label_order = list(label_order)\n",
    "    if not distlist:\n",
    "        return np.empty((0, len(label_order))), np.empty((0,))\n",
    "    probs, weights = [], []\n",
    "    for item in distlist:\n",
    "        lookup = {d['label']: d['score'] for d in item['scores']}\n",
    "        probs.append([lookup[label] for label in label_order])\n",
    "        weights.append(item['n_tokens'])\n",
    "    return np.array(probs), np.array(weights)\n",
    "\n",
    "def aggregate_sentiment(distlist: List[Dict], label_order: Iterable[str] = LABEL_ORDER) -> Dict[str, float]:\n",
    "    label_order = list(label_order)\n",
    "    if not distlist:\n",
    "        return {\n",
    "            **{f'p_{lab}_wmean': float('nan') for lab in label_order},\n",
    "            **{f'p_{lab}_std': float('nan') for lab in label_order},\n",
    "            **{f'p_{lab}_q95': float('nan') for lab in label_order},\n",
    "            **{f'p_{lab}_q05': float('nan') for lab in label_order},\n",
    "            **{f'share_{lab}_gt70': float('nan') for lab in label_order},\n",
    "            'entropy_wmean': float('nan'),\n",
    "            'n_chunks': 0,\n",
    "            'n_tokens_total': 0,\n",
    "            'max_positive': float('nan'),\n",
    "            'max_negative': float('nan'),\n",
    "        }\n",
    "    probs, weights = distlist_to_array(distlist, label_order)\n",
    "    total_tokens = weights.sum()\n",
    "    w = weights / total_tokens if total_tokens > 0 else np.ones_like(weights) / len(weights)\n",
    "\n",
    "    features: Dict[str, float] = {}\n",
    "    for j, label in enumerate(label_order):\n",
    "        pj = probs[:, j]\n",
    "        features[f'p_{label}_wmean'] = float((pj * w).sum())\n",
    "        features[f'p_{label}_std'] = float(pj.std())\n",
    "        features[f'p_{label}_q95'] = float(np.quantile(pj, 0.95))\n",
    "        features[f'p_{label}_q05'] = float(np.quantile(pj, 0.05))\n",
    "        features[f'share_{label}_gt70'] = float((pj > 0.70).mean())\n",
    "    entropy = -(probs * np.log(probs + 1e-12)).sum(axis=1)\n",
    "    features['entropy_wmean'] = float((entropy * w).sum())\n",
    "    features['n_chunks'] = int(len(distlist))\n",
    "    features['n_tokens_total'] = int(total_tokens)\n",
    "    features['max_positive'] = float(probs[:, label_order.index('positive')].max()) if 'positive' in label_order else float('nan')\n",
    "    features['max_negative'] = float(probs[:, label_order.index('negative')].max()) if 'negative' in label_order else float('nan')\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5e556",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b32e60",
   "metadata": {},
   "source": [
    "## Transcript-level wrapper\n",
    "Collect ID metadata, apply scoring, and build a dataframe of engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c911adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_transcript(text: str) -> Dict[str, float]:\n",
    "    sentences = split_sentences(text)\n",
    "    chunks = pack_sentences_to_token_chunks(sentences, tokenizer)\n",
    "    distributions = score_chunks(chunks) if chunks else []\n",
    "    features = aggregate_sentiment(distributions)\n",
    "    features['n_sentences'] = len(sentences)\n",
    "    return features\n",
    "\n",
    "def score_dataframe(df: pd.DataFrame, text_column: str, id_columns: List[str]) -> pd.DataFrame:\n",
    "    records = []\n",
    "    id_columns = [col for col in id_columns if col in df.columns]\n",
    "    for row in tqdm(df.itertuples(index=False), total=len(df)):\n",
    "        payload = {col: getattr(row, col) for col in id_columns}\n",
    "        text = getattr(row, text_column)\n",
    "        payload.update(score_transcript(text))\n",
    "        records.append(payload)\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f779d2",
   "metadata": {},
   "source": [
    "## Run the sentiment pipeline\n",
    "Use the cache to avoid recomputation on repeated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b33ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "INFO: Generated sentiment features for 10 transcripts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>p_positive_wmean</th>\n",
       "      <th>p_positive_std</th>\n",
       "      <th>p_positive_q95</th>\n",
       "      <th>p_positive_q05</th>\n",
       "      <th>share_positive_gt70</th>\n",
       "      <th>p_negative_wmean</th>\n",
       "      <th>p_negative_std</th>\n",
       "      <th>...</th>\n",
       "      <th>p_neutral_std</th>\n",
       "      <th>p_neutral_q95</th>\n",
       "      <th>p_neutral_q05</th>\n",
       "      <th>share_neutral_gt70</th>\n",
       "      <th>entropy_wmean</th>\n",
       "      <th>n_chunks</th>\n",
       "      <th>n_tokens_total</th>\n",
       "      <th>max_positive</th>\n",
       "      <th>max_negative</th>\n",
       "      <th>n_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469938</td>\n",
       "      <td>0.311108</td>\n",
       "      <td>0.931317</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.145280</td>\n",
       "      <td>0.217575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329131</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.612724</td>\n",
       "      <td>25</td>\n",
       "      <td>10374</td>\n",
       "      <td>0.956435</td>\n",
       "      <td>0.867143</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565958</td>\n",
       "      <td>0.337969</td>\n",
       "      <td>0.958179</td>\n",
       "      <td>0.097367</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.050713</td>\n",
       "      <td>0.091793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324060</td>\n",
       "      <td>0.885707</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.537771</td>\n",
       "      <td>22</td>\n",
       "      <td>9341</td>\n",
       "      <td>0.959201</td>\n",
       "      <td>0.454530</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.357049</td>\n",
       "      <td>0.260738</td>\n",
       "      <td>0.943069</td>\n",
       "      <td>0.080761</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142774</td>\n",
       "      <td>0.226975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279511</td>\n",
       "      <td>0.869540</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>28</td>\n",
       "      <td>11865</td>\n",
       "      <td>0.953654</td>\n",
       "      <td>0.850958</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463796</td>\n",
       "      <td>0.305944</td>\n",
       "      <td>0.953290</td>\n",
       "      <td>0.097362</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304609</td>\n",
       "      <td>0.871286</td>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.560847</td>\n",
       "      <td>25</td>\n",
       "      <td>10786</td>\n",
       "      <td>0.959866</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>0.483510</td>\n",
       "      <td>0.312496</td>\n",
       "      <td>0.957271</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.051944</td>\n",
       "      <td>0.076311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304825</td>\n",
       "      <td>0.872078</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.593212</td>\n",
       "      <td>26</td>\n",
       "      <td>11086</td>\n",
       "      <td>0.959664</td>\n",
       "      <td>0.367326</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  quarter  p_positive_wmean  p_positive_std  p_positive_q95  \\\n",
       "0      A  2010        1          0.469938        0.311108        0.931317   \n",
       "1      A  2010        2          0.565958        0.337969        0.958179   \n",
       "2      A  2011        1          0.357049        0.260738        0.943069   \n",
       "3      A  2011        2          0.463796        0.305944        0.953290   \n",
       "4      A  2011        3          0.483510        0.312496        0.957271   \n",
       "\n",
       "   p_positive_q05  share_positive_gt70  p_negative_wmean  p_negative_std  ...  \\\n",
       "0        0.107376             0.360000          0.145280        0.217575  ...   \n",
       "1        0.097367             0.454545          0.050713        0.091793  ...   \n",
       "2        0.080761             0.142857          0.142774        0.226975  ...   \n",
       "3        0.097362             0.280000          0.024212        0.012790  ...   \n",
       "4        0.081136             0.269231          0.051944        0.076311  ...   \n",
       "\n",
       "   p_neutral_std  p_neutral_q95  p_neutral_q05  share_neutral_gt70  \\\n",
       "0       0.329131       0.848629       0.025148            0.280000   \n",
       "1       0.324060       0.885707       0.020418            0.272727   \n",
       "2       0.279511       0.869540       0.040421            0.250000   \n",
       "3       0.304609       0.871286       0.026085            0.320000   \n",
       "4       0.304825       0.872078       0.027633            0.307692   \n",
       "\n",
       "   entropy_wmean  n_chunks  n_tokens_total  max_positive  max_negative  \\\n",
       "0       0.612724        25           10374      0.956435      0.867143   \n",
       "1       0.537771        22            9341      0.959201      0.454530   \n",
       "2       0.678462        28           11865      0.953654      0.850958   \n",
       "3       0.560847        25           10786      0.959866      0.053804   \n",
       "4       0.593212        26           11086      0.959664      0.367326   \n",
       "\n",
       "   n_sentences  \n",
       "0          324  \n",
       "1          388  \n",
       "2          504  \n",
       "3          517  \n",
       "4          524  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = score_dataframe(transcripts_df, TEXT_COLUMN, ID_COLUMNS)\n",
    "logging.info('Generated sentiment features for %s transcripts', len(sentiment_df))\n",
    "sentiment_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2b32",
   "metadata": {},
   "source": [
    "## Save features to disk\n",
    "Persist the results for downstream regression and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33222d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Wrote sentiment features to output/sentiment_features.parquet\n",
      "INFO: Also exported CSV for quick inspection.\n"
     ]
    }
   ],
   "source": [
    "sentiment_df.to_parquet(OUTPUT_FILE, index=False)\n",
    "logging.info('Wrote sentiment features to %s', OUTPUT_FILE)\n",
    "sentiment_df.to_csv(OUTPUT_DIR / 'sentiment_features.csv', index=False)\n",
    "logging.info('Also exported CSV for quick inspection.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a7c63",
   "metadata": {},
   "source": [
    "## Feature sanity checks\n",
    "Inspect distributions to ensure probabilities and engineered metrics look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81244bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_positive_wmean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.407108</td>\n",
       "      <td>0.118934</td>\n",
       "      <td>0.181178</td>\n",
       "      <td>0.366681</td>\n",
       "      <td>0.446662</td>\n",
       "      <td>0.480117</td>\n",
       "      <td>0.565958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_positive_std</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.270518</td>\n",
       "      <td>0.066509</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.297990</td>\n",
       "      <td>0.311106</td>\n",
       "      <td>0.337969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_positive_q95</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.843561</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.447004</td>\n",
       "      <td>0.836436</td>\n",
       "      <td>0.924079</td>\n",
       "      <td>0.950735</td>\n",
       "      <td>0.958179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_positive_q05</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.076360</td>\n",
       "      <td>0.025031</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>0.065108</td>\n",
       "      <td>0.082061</td>\n",
       "      <td>0.094411</td>\n",
       "      <td>0.107376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_negative_wmean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.169827</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.144027</td>\n",
       "      <td>0.233111</td>\n",
       "      <td>0.365886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_negative_std</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.201827</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.120442</td>\n",
       "      <td>0.222275</td>\n",
       "      <td>0.273836</td>\n",
       "      <td>0.333768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_negative_q95</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.545176</td>\n",
       "      <td>0.312926</td>\n",
       "      <td>0.050775</td>\n",
       "      <td>0.291056</td>\n",
       "      <td>0.657921</td>\n",
       "      <td>0.710062</td>\n",
       "      <td>0.905505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_negative_q05</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.014240</td>\n",
       "      <td>0.023306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_neutral_wmean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.423065</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>0.292837</td>\n",
       "      <td>0.383692</td>\n",
       "      <td>0.438972</td>\n",
       "      <td>0.477512</td>\n",
       "      <td>0.511992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_neutral_std</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.290442</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.254873</td>\n",
       "      <td>0.274615</td>\n",
       "      <td>0.288959</td>\n",
       "      <td>0.304771</td>\n",
       "      <td>0.329131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_neutral_q95</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.837799</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.713916</td>\n",
       "      <td>0.832648</td>\n",
       "      <td>0.851657</td>\n",
       "      <td>0.870849</td>\n",
       "      <td>0.885707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_neutral_q05</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.025382</td>\n",
       "      <td>0.032531</td>\n",
       "      <td>0.045720</td>\n",
       "      <td>0.061794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      mean       std       min       25%       50%  \\\n",
       "p_positive_wmean   10.0  0.407108  0.118934  0.181178  0.366681  0.446662   \n",
       "p_positive_std     10.0  0.270518  0.066509  0.131009  0.262847  0.297990   \n",
       "p_positive_q95     10.0  0.843561  0.177143  0.447004  0.836436  0.924079   \n",
       "p_positive_q05     10.0  0.076360  0.025031  0.031882  0.065108  0.082061   \n",
       "p_negative_wmean   10.0  0.169827  0.118489  0.024212  0.069605  0.144027   \n",
       "p_negative_std     10.0  0.201827  0.107209  0.012790  0.120442  0.222275   \n",
       "p_negative_q95     10.0  0.545176  0.312926  0.050775  0.291056  0.657921   \n",
       "p_negative_q05     10.0  0.014426  0.003524  0.010989  0.012589  0.013637   \n",
       "p_neutral_wmean    10.0  0.423065  0.073032  0.292837  0.383692  0.438972   \n",
       "p_neutral_std      10.0  0.290442  0.025914  0.254873  0.274615  0.288959   \n",
       "p_neutral_q95      10.0  0.837799  0.050987  0.713916  0.832648  0.851657   \n",
       "p_neutral_q05      10.0  0.035277  0.014196  0.018088  0.025382  0.032531   \n",
       "\n",
       "                       75%       max  \n",
       "p_positive_wmean  0.480117  0.565958  \n",
       "p_positive_std    0.311106  0.337969  \n",
       "p_positive_q95    0.950735  0.958179  \n",
       "p_positive_q05    0.094411  0.107376  \n",
       "p_negative_wmean  0.233111  0.365886  \n",
       "p_negative_std    0.273836  0.333768  \n",
       "p_negative_q95    0.710062  0.905505  \n",
       "p_negative_q05    0.014240  0.023306  \n",
       "p_neutral_wmean   0.477512  0.511992  \n",
       "p_neutral_std     0.304771  0.329131  \n",
       "p_neutral_q95     0.870849  0.885707  \n",
       "p_neutral_q05     0.045720  0.061794  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_cols = [col for col in sentiment_df.columns if col.startswith('p_')]\n",
    "sentiment_df[prob_cols].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c2f7dd",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGGCAYAAADmRxfNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQYdJREFUeJzt3Ql4FGW2+P8TkhAIwypCCEZAQRCUfYhBFLiGbbgIelUWR5aL4KDMFVEYcWQTFUVEUFAURMQRQRzFe0dkHYFBtmFzBQYQRPZFIUAEAqn/c97/r3q6O52kO5Wi0+nv53mK0NXV1VWn3uquU+/SMZZlWQIAAAAADpRw8mIAAAAAUCQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBZABBszZozExMRckfdq06aNmWwrV6407/3RRx9dkffv27ev1KxZU4qys2fPyoMPPihJSUkmNkOGDAnbtuj7a/ko6GsHDx4s4eRf3iL1vJs9e7ZZdt++fVJc2fu4adOmQlunHvubbrop3+U0rvreug15HR/97NDPkEgve0BRR2IBFLEvZ3sqVaqUJCcnS4cOHeTVV1+VM2fOFMr7HDp0yHzxbtu2TYqaorxtwXj++efNcRw0aJC899578sADD0hxtnbtWnO8Tp06JdFOj/3ChQvDvRkI0vfff2/KbnFO+IBwiAvLuwLI1TPPPCO1atWSrKwsOXLkiKkZ0DvfkyZNkv/93/+Vhg0bepZ9+umn5cknnwz54n3s2LHmDl7jxo2Dft3SpUvFbXlt24wZMyQ7O1uKsr///e9yyy23yOjRo8O9KfLrr79KXFyc64mFHi+9E1yhQgWJFoHOO00s7rnnHunWrZvPfE0ue/ToIQkJCVd4K6NDjRo1TFmPj4/Pc7mdO3dKiRIlfBILLbtaM+FfE3olPuuA4orEAihiOnXqJM2bN/c8HjFihLlg/c///E+58847Zfv27VK6dGnznF44un3xmJmZKYmJiVKyZEkJp/wuHIqCY8eOSf369aUo0BovuCOU8y42NtZMkUQT+IsXL0ZEGbJrd/MTSmIX7s86IJLRFAqIAP/xH/8hI0eOlB9//FH+8pe/5NmWeNmyZdKqVStzB/k3v/mN1K1bV5566inznNZ+/Pa3vzX/79evn6fZld0+2W7XvHnzZrn99ttNQmG/Nrd2x5cvXzbLaL+CMmXKmOTnp59+Cqp9s/c689u2QH0szp07J48//rikpKSYCwfd14kTJ4plWQH7DGhTFd0/XbZBgwayePHioBOG/v37S9WqVc1FTKNGjeTdd9/N0d9k79698tlnn3m2PbdmFnfffbc0bdrUZ16XLl3Ma7RWyrZhwwYz7/PPP/fM02ZHWoNl73Pt2rXlxRdfzFGbE6iPhW6nJq26D9dff728+eabefYXyCte+rphw4aZ/2sNW6B91rLarFkzkwhXqlTJ3Ln3LxvqrbfeMtujy7Vo0UL+8Y9/SLDsY/v++++b46/7pu+5evXqHMtu3brVJO7lypUz58Ydd9wh69ev91lGawr1TnadOnXMuq666ipzPul55b3v3jHT/2tZ1DJhx8Eu7/59LPQGwXXXXRdwX9LS0nxuKoQSQ3/2Nu7YsUPuu+8+s8+6L48++qicP38+1xjqcdbjbR/rYGLmfRPioYceMu+jy/fu3Vt++eUXn2U+/fRT6dy5s2nmqe+jx33cuHHmcyQQ/Sxq2bKl2X8tZ9OnT8+3j0Ug3p9Buuy9995r/t+2bVvPMdPzI7fPugsXLpiaSD3fdLv1/Bs+fLiZH+znLxANqLEAIoQ2qdAvKK2mHzBgQMBlvvvuO3Phos2ltEmVfgHu3r1bvvzyS/P8jTfeaOaPGjVKBg4cKLfddpuZr1/ctpMnT5oLCb2A+f3vf28upvPy3HPPmS/lP/3pT+YCfPLkyZKenm76Sdg1K8EIZtu8afKgScwXX3xhLvq16dSSJUvMxe7BgwfllVde8Vl+zZo18vHHH8vDDz8sZcuWNf1W/uu//kv2799vLoRyo80s9CJD46gXX3pxs2DBAnORohf5eqGm2659Kh577DG55pprTLKjrr766oDr1H3TC6yMjAxzAab7osdIm2roRbXul9L/67xbb73Vc+HWunVrs396AXfttdea5khaq3X48GET+9zoBWLHjh2lWrVq5sJZL+Q03rltY37x0uToX//6l3zwwQcm1pUrV/bZZy0XmgzrRa12aD9+/Li89tprJmHVbbGbTr399ttmX/Q4a8L0ww8/mP3Xi2i9eAvGqlWrZP78+fI///M/psy//vrrZl83btzo6QCs54bGXeOtF4RaA6aJlR5bfX1qaqrngnz8+PFmmzXJ0WOknZK3bNki7dq1C/j+euzt5bXsKr1gDqR79+7mgvuf//ynJ5FWetNAL9hfeuklz7xgY5gXfa1eVOs+6fr1OOrF/pw5c3yW01rRDz/80JRxPZb6mmBjZtPX6jZpDLXp0RtvvGH2y0687Yt6veAeOnSo+avvq+e8xtl735Vu5+9+9zuzDz179jTbp/2XtEbhv//7v6WgNH5aVjQW+pmq56+y//rTpF3LpJ4Tenx1uW+++caUez0H7L41+X3+AlHBAlAkvPPOO3qb3frnP/+Z6zLly5e3mjRp4nk8evRo8xrbK6+8Yh4fP34813Xo+nUZfT9/rVu3Ns9Nnz494HM62b744guzbPXq1a2MjAzP/A8//NDMnzJlimdejRo1rD59+uS7zry2TV+v67EtXLjQLPvss8/6LHfPPfdYMTEx1u7duz3zdLmSJUv6zPvqq6/M/Ndee83Ky+TJk81yf/nLXzzzLl68aKWlpVm/+c1vfPZdt69z5855rs97PxctWmQef/311+bxvffea6WmpnqWu/POO32O97hx46wyZcpY//rXv3zW9+STT1qxsbHW/v37ffZZy4etS5cuVmJionXw4EHPvF27dllxcXE+ZSiUeL300ktm3t69e31ev2/fPrM9zz33nM/8b775xryfPV/jWKVKFatx48bWhQsXPMu99dZbZr3eZSM3upxOmzZt8sz78ccfrVKlSll33XWXZ163bt3MPu3Zs8cz79ChQ1bZsmWt22+/3TOvUaNG+R5D//NO6XEJVMbt89qO0enTp62EhATr8ccf91luwoQJptzqtocSw/y2UcuQt4cfftjM1+Np08clSpSwvvvuO59lg42ZvY/NmjUzx9R7n3T+p59+6pmXmZmZY1sfeughUzbPnz+f47Po5Zdf9szTMqJlRcuM/T4aV//PjEDHx/8zaMGCBWYZ/RzL73PpvffeM/H5xz/+4bOcfk7qOr788sugP3+B4o6mUEAE0Tt8eY0OZd/B1LvhBe3orHfZtClSsPTuq97RtmkHVr0rvmjRInGTrl/bruudR29aW6DXSt7Nh5TWonjfRda7inonVu+Q5/c+2sxL75ja9M6tvq8OL6t3bkPVpEkTcyzt5jpaM6E1HRpLvTOuNRO6D3qH1K65UVpToo8rVqwoJ06c8Ey6b1oDEaj5j9Lnli9fbjoWaxMUmzbr0NqpQAoaL6U1HVr+9E6z93ZqHLWJkdYyKa0J0FquP/zhDz7t2rU2qHz58hIsbUKkzYVsWpPTtWtXU4Ol+66T1vTp/ns3Q9Jy2qtXLxNnvWNun0N653nXrl3iBo2hxlzvvns32dMaF+34r9seSgzz88gjj/g8/uMf/2j++p+fWhPm3T8olJjZ9G6+d18orV3Qvije7+Vdi6mfZbpPWqa1zGuzLW/6Wq3NsmkZ0cdaZrSJ1JWi553WUtSrV8/nWGgTVWUfi8L4/AUiHYkFEEH0Qtb7Ij5QMwttNqPNJrQJkzZn0guYUL7kqlevHlLnRb3I8aZNHvSC1e1hHLWJhV4k+8fDbs6gz3uzL9i86QW6fxvwQO+j++g9okxe7xMMTYj0YtjuS6B/9eJK22brBZ02WdFRa37++WefxEIvdrXtuzY38p40CVB6wRWIztcmXXpc/AWa5yRe9nbqRbPGzX9bdfABezvt2PmXIb04za0fQiD+r1c33HCDuVjV5kM66f+1vbs/PY56ftj9FrQJizZx09fffPPNpmnd119/LYVJz1N9v3Xr1pnHe/bsMRfKOj/UGIYaG00WtSz7n5/axM9bKDHL7b00edZExPu9NGm76667TOKoSZbujza5VKdPn/Z5vZ7f2m/Lmx4XdSWHidVjodvtfxzsbbGPRWF8/gKRjj4WQIQ4cOCA+eLN7ULQvhuod631Dpp2ItaLUL0TqnfW9O5jMKPThNIvIli5dQ7Wi+grNWJObu/j39H7StEkQtvQa0daTSz+/Oc/mzue2idAH9t9W7wTC71A0Xb+2t49EPtCJ9zx0u20O50HWo9ecBZV2v5eL/T1rrOeMzNnzjRt6bXTsF4wFgbtqK8DI+hFp/Yt0b96sW93KHYzhrmdi26c9/40YdOaEU0oNIHTJEc7yGstnfbRKqoX4LpdmmTqkN+B2H2BCuPzF4h0JBZAhNAOokp/MC8veoGiI7fopF+EOr6+XrTql53e2S7sX+r2bzKiF57aYdH79zb0TnegH1HTO9bed6ZD2TYdv16b92hzCu9aC7s5hT5fGHQ9esdaLy68ay2cvo8mDDqkp3Z+1s7YdgKhF7Z2YqGJgnfneb0Q01oru4YiWFWqVDEXcHpc/AWaF6zcjpdup5YDvQueV7Jjx07LkN2sxB6ZSUfY0tG3ghGo2ZJ2qtWLd7szuf5fOxT70+Oox9W7o7h2HNfmgDppvPWYaIfkvBKLUMqu3oXXTr7axEbPUb341OPv3Uwt2BgGExvv2gg93lqW8/sVe41bKDGz30tHWbJp7HRQAe2ArbQTtw4Ooc28NKY2Pda5/a6NjrblXWuhx1Xlt/35CeV46bH46quvzGdqfq/L7/MXKO5oCgVEAB05RYdk1AuE+++/P9fltOmMP/uH5uxhEe0v6cL6tWQdXca738dHH31kLia82+7rF7M279ELadvf/va3HE0pQtk2vVjRGo+pU6f6zNe7y/rln1vfgVDp++gPFerFn+3SpUtmdB69a6x3YAtCR9TRJj86VKxeyOown0ovMDVW2nfDu7ZCaXt7bT6jfQf8acx0uwLRO6V6UaOj1+jFmvdFpn9flFDkdrx0xCh9Tx19yr+GQx/rxaXSoVX1AlZrA7zLho4cFEr51JjoXW+bliutcWjfvr3ndyT0/zrPuwnN0aNHZe7cuab2SO+iK3vbbHqMtZbQf1jRQLEIZZu12YweC60R0YtW72ZQocQwP9OmTfN5rOVW5Xd+hBIz72GDNSm06ahQWibt97Lv2Hvvjx53HcUrEH2tjkLlvaw+1jLj3aemIEL5rNHzTpN//ZFOf9rEUJOfYD9/geKOGgugiNELPb0jqF+q+iWuSYWOja53d/U3DvL6MShtXqBV8TpOvC6vbX/1S1s7BuuFgH2Rr01u9GJO7/TrF6xe5Pq3sQ6WXhTruvXurm6vDnmqF2LeQ+LqnV5NOHQIUP2S1qYmOj6//5CcoWybNifRu6N6N1AvfPTutjY30AshHbY0t+E+Q6UdUvViRjsUazt4vVOq+6JDSOq+5tXnJS96N1gvjjSJsH/DQumdXL1Q0ck/sdD2/loG9G63bo++XpfToS91mzQO9rCv/vSOu8ZH24Brp1o7KdOmVzo0cEHYF3d6DLQ9uSZKui8a+2effdYMg6vbpB2ANU56Z/qTTz4xMX3iiSfM8rqcdsjVGgu9uNZl3nnnnZD6WOg+aE2e93CzSi/Kbfo+9m8M6BC62jFYj6te8E2YMMGznHZg1uFUdd+0bGsHc42tDqWaXyy0Bk3vUmvNg5ZZ/+FY/RNWjYnGQS+4dShfb8HGMD+6vA6VqueeJmB63mnn62Bqg4KNmfeFv96p13Ncazr0OOhr7eGTtdmX1l726dPHHCst81oTm1vzOo2jJt66/1pro8m9llVNYJz+YKZe8Gvcdf3axFTLjZZBrd0LNNS3NlfTQQa05kHPIT1/9HNa52uir0lyMJ+/QLEX7mGpAPgO2WhPOsxjUlKS1a5dOzN0q/ewprkNq7hixQqra9euVnJysnm9/u3Zs2eO4Ul1+Mf69et7hhq1h2rUIRYbNGgQcPtyG272gw8+sEaMGGGGgCxdurQZqtMeMtObDhupQ9PqUJu33nqrGR7Uf515bZv/cLPqzJkz1mOPPWb2Mz4+3qpTp44ZAjU7O9tnOV3PI488kmObchsG19/Ro0etfv36WZUrVzZxvfnmmwMOiRvscLO2YcOGmW178cUXfebXrl3bzPce5tN7nzXeuoxui25Ty5YtrYkTJ/oM9ek/3KxdPnT4Wn3d9ddfb82cOdMMe6pDsxY0XjoErh5XHY7Tf+jZv/71r1arVq3MUKw61atXz6x3586dPut4/fXXrVq1apmy0bx5c2v16tUBy0Yg9rbqcMB6/HUduo+BhhHdsmWL1aFDBzNMsA5v2rZtW2vt2rU+y+jwxS1atLAqVKhgyrNusw7t6h3bQMOZ7tixwwzBqq/R5+w4+Q836+3+++83z6Wnp+e6f8HG0J+9jd9//70ZglmHiK1YsaI1ePBg69dffw0Yw0CCiZm9j6tWrbIGDhxo3keX1/07efKkz7I6NOstt9xi4qTn7fDhw60lS5bkGPrV/izSzwkd2lnLqJa/qVOn+qyvoMPNqhkzZljXXXedGdbX+/0DlT09/nqe6jZpGdN91OF1x44da4YQDuXzFyjOYvSfcCc3AIDw0Dvhbg6v6ja9661Dqvo3iYt2WkOlNTY6ulNutVgAUNjoYwEAUULbg3vTZEJ/Y0Cb/gAA4BR9LAAgSmi/Be2boX91RC7tXKu/WZLb8LUAAISCxAIAooR24NXhbXWUK+2sqj/Sp8NhBvqBOQAAQkUfCwAAAACO0ccCAAAAgGMkFgAAAAAcKxZ9LLKzs80vmOqPB9k/MgUAAADAGe01cebMGfOjlSVKlCj+iYUmFSkpKeHeDAAAAKBY+umnn8wvyRf7xEJrKuwdLleunESrrKwsWbp0qbRv317i4+PDvTnFBnF1B3F1D7F1B3F1B3F1B3F1RzTGNSMjw9zAt6+3i31iYTd/0qQi2hOLxMREE4NoKexXAnF1B3F1D7F1B3F1B3F1B3F1RzTHNSaI7gZ03gYAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAArmxiMX78ePntb39rfnmvSpUq0q1bN9m5c2e+r1uwYIHUq1dPSpUqJTfffLMsWrTI53nLsmTUqFFSrVo1KV26tKSnp8uuXbtC3xsAAAAART+xWLVqlTzyyCOyfv16WbZsmfn1Qf1J83PnzuX6mrVr10rPnj2lf//+snXrVpOM6PTtt996lpkwYYK8+uqrMn36dNmwYYOUKVNGOnToIOfPn3e2dwAAAACuiLhQFl68eLHP49mzZ5uai82bN8vtt98e8DVTpkyRjh07yrBhw8zjcePGmaRk6tSpJpHQ2orJkyfL008/LV27djXLzJkzR6pWrSoLFy6UHj16FHzvAAAAABT9PhanT582fytVqpTrMuvWrTNNm7xpbYTOV3v37pUjR474LFO+fHlJTU31LAMAAACgGNVYeMvOzpYhQ4bIrbfeKjfddFOuy2nSoLUP3vSxzreft+fltoy/CxcumMmWkZFh/mrTLJ2ilb3v0RwDNxBXdxBX9xBbdxBXdxBXdxBXd0RjXLNC2NcCJxba10L7SaxZs0auNO1EPnbs2Bzzly5dKomJiRLttKkZCh9xdQdxdQ+xdQdxdQdxdQdxdUc0xTUzM9PdxGLw4MHyt7/9TVavXi3XXHNNnssmJSXJ0aNHfebpY51vP2/P01GhvJdp3LhxwHWOGDFChg4d6lNjkZKSYjqSlytXTqKVZpRa0Nu1ayfx8fHh3pxig7i6g7i6h9i6g7hGZlwHv79FIsnU+5sWynoor+6Ixrhm/L+WQYWeWGhH6z/+8Y/yySefyMqVK6VWrVr5viYtLU1WrFhhmk3Z9IDofKXr0ORCl7ETCd0BHR1q0KBBAdeZkJBgJn96gKPlIOeFOLiDuLqDuLqH2LqDuEZWXC9F2E92FXYMKK/uiKa4xoewn3GhNn+aO3eufPrpp+a3LOw+ENrZWn9/QvXu3VuqV69umiupRx99VFq3bi0vv/yydO7cWebNmyebNm2St956yzwfExNjko5nn31W6tSpYxKNkSNHSnJyshmWFgAAAEDRF1Ji8cYbb5i/bdq08Zn/zjvvSN++fc3/9+/fLyVK/PvuQMuWLU0yosPJPvXUUyZ50GFkvTt8Dx8+3PwWxsCBA+XUqVPSqlUrM7St/qAeAAAAgKIv5KZQ+dEmUv7uvfdeM+VGay2eeeYZMwEAAACIPJHV8BAAAABAkURiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAALjyicXq1aulS5cukpycLDExMbJw4cI8l+/bt69Zzn9q0KCBZ5kxY8bkeL5evXoF2yMAAAAART+xOHfunDRq1EimTZsW1PJTpkyRw4cPe6affvpJKlWqJPfee6/PcppoeC+3Zs2aUDcNAAAAQJjEhfqCTp06mSlY5cuXN5NNazh++eUX6devn++GxMVJUlJSqJsDAAAAIBITC6fefvttSU9Plxo1avjM37Vrl2leVapUKUlLS5Px48fLtddeG3AdFy5cMJMtIyPD/M3KyjJTtLL3PZpj4Abi6g7i6h5i6w7iGplxjZNsiSSFFQfKqzuiMa5ZIexrjGVZVkHfSPtCfPLJJ9KtW7eglj906JBJFubOnSv33XefZ/7nn38uZ8+elbp165pmUGPHjpWDBw/Kt99+K2XLls2xHu2Tocv40/UmJiYWdHcAAAAAeMnMzJRevXrJ6dOnpVy5clJkEguthXj55ZdNglGyZMlclzt16pSp0Zg0aZL0798/qBqLlJQUOXHiRL47XNwzymXLlkm7du0kPj4+3JtTbBBXdxBX9xBbdxDXyIzr4Pe3SCSZen/TQlkP5dUd0RjXjIwMqVy5clCJxRVrCqX5y6xZs+SBBx7IM6lQFSpUkBtuuEF2794d8PmEhAQz+dMDHC0HOS/EwR3E1R3E1T3E1h3ENbLieinCRtYv7BhQXt0RTXGND2E/r9jZtmrVKpMoBKqB8KfNovbs2SPVqlW7ItsGAAAAwJmQEwu96N+2bZuZ1N69e83/9+/fbx6PGDFCevfuHbDTdmpqqtx00005nnviiSdM4rFv3z5Zu3at3HXXXRIbGys9e/Ys2F4BAAAAuKJCbgq1adMmadu2refx0KFDzd8+ffrI7NmzTedrO8mwaZusv/71r+Y3LQI5cOCASSJOnjwpV199tbRq1UrWr19v/g8AAACgGCYWbdq0Mf0lcqPJhT/9HQvtUZ6befPmhboZAAAAAIqQyOrRBAAAAKBIIrEAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAIArn1isXr1aunTpIsnJyRITEyMLFy7Mc/mVK1ea5fynI0eO+Cw3bdo0qVmzppQqVUpSU1Nl48aNoe8NAAAAgMhILM6dOyeNGjUyiUAodu7cKYcPH/ZMVapU8Tw3f/58GTp0qIwePVq2bNli1t+hQwc5duxYqJsHAAAAIAziQn1Bp06dzBQqTSQqVKgQ8LlJkybJgAEDpF+/fubx9OnT5bPPPpNZs2bJk08+GfJ7AQAAACimfSwaN24s1apVk3bt2smXX37pmX/x4kXZvHmzpKen/3ujSpQwj9etW3elNg8AAADAlayxCJUmE1oD0bx5c7lw4YLMnDlT2rRpIxs2bJCmTZvKiRMn5PLly1K1alWf1+njHTt2BFynrkcnW0ZGhvmblZVlpmhl73s0x8ANxNUdxNU9xNYdxDUy4xon2RJJCisOlFd3RGNcs0LY1xjLsqyCvpF2wv7kk0+kW7duIb2udevWcu2118p7770nhw4dkurVq8vatWslLS3Ns8zw4cNl1apVJgHxN2bMGBk7dmyO+XPnzpXExMQC7g0AAAAAb5mZmdKrVy85ffq0lCtXTsJaYxFIixYtZM2aNeb/lStXltjYWDl69KjPMvo4KSkp4OtHjBhhOnt711ikpKRI+/bt893h4p5RLlu2zDQ3i4+PD/fmFBvE1R3E1T3E1h3ENTLjOvj9LRJJpt7ftFDWQ3l1RzTGNeP/tQwKRlgSi23btpkmUqpkyZLSrFkzWbFihafmIzs72zwePHhwwNcnJCSYyZ8e4Gg5yHkhDu4gru4gru4htu4grpEV10sR9pNdhR0Dyqs7oimu8SHsZ8iJxdmzZ2X37t2ex3v37jWJQqVKlUzzJq1NOHjwoMyZM8c8P3nyZKlVq5Y0aNBAzp8/b/pY/P3vf5elS5d61qG1D3369DH9MLQ2Q1+jw9rao0QBAAAAKNpCTiw2bdokbdu29Ty2myRpYjB79mzzGxX79+/3GfXp8ccfN8mG9n9o2LChLF++3Gcd3bt3l+PHj8uoUaPMD+fpCFKLFy/O0aEbAAAAQDFJLHREp7z6e2ty4U07YeuUH232lFvTJwAAAABFW2Q1PAQAAABQJJFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAAK58YrF69Wrp0qWLJCcnS0xMjCxcuDDP5T/++GNp166dXH311VKuXDlJS0uTJUuW+CwzZswYsy7vqV69eqHvDQAAAIDISCzOnTsnjRo1kmnTpgWdiGhisWjRItm8ebO0bdvWJCZbt271Wa5BgwZy+PBhz7RmzZpQNw0AAABAmMSF+oJOnTqZKViTJ0/2efz888/Lp59+Kv/3f/8nTZo0+feGxMVJUlJSqJsDAAAAIBITC6eys7PlzJkzUqlSJZ/5u3btMs2rSpUqZZpLjR8/Xq699tqA67hw4YKZbBkZGeZvVlaWmaKVve/RHAM3EFd3EFf3EFt3ENfIjGucZEskKaw4UF7dEY1xzQphX2Msy7IK+kbaF+KTTz6Rbt26Bf2aCRMmyAsvvCA7duyQKlWqmHmff/65nD17VurWrWuaQY0dO1YOHjwo3377rZQtWzbHOrRPhi7jb+7cuZKYmFjQ3QEAAADgJTMzU3r16iWnT582/aWLTGKhF/4DBgwwTaHS09NzXe7UqVNSo0YNmTRpkvTv3z+oGouUlBQ5ceJEvjtc3DPKZcuWmT4t8fHx4d6cYoO4uoO4uofYuoO4RmZcB7+/RSLJ1PubFsp6KK/uiMa4ZmRkSOXKlYNKLK5YU6h58+bJgw8+KAsWLMgzqVAVKlSQG264QXbv3h3w+YSEBDP50wMcLQc5L8TBHcTVHcTVPcTWHcQ1suJ6KcJG1i/sGFBe3RFNcY0PYT+vyNn2wQcfSL9+/czfzp0757u8Novas2ePVKtW7UpsHgAAAACHQq6x0It+75qEvXv3yrZt20xnbO1sPWLECNM/Ys6cOZ7mT3369JEpU6ZIamqqHDlyxMwvXbq0lC9f3vz/iSeeMEPQavOnQ4cOyejRoyU2NlZ69uzpdP8AAAAAXAEh11hs2rTJDBNrDxU7dOhQ8/9Ro0aZx9r5ev/+/Z7l33rrLbl06ZI88sgjpgbCnh599FHPMgcOHDBJhHbevu++++Sqq66S9evXmx/VAwAAAFAMayzatGkjefX3nj17ts/jlStXBtX/AgAAAEDkiqweTQAAAACKJBILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAwJVPLFavXi1dunSR5ORkiYmJkYULF+b7mpUrV0rTpk0lISFBateuLbNnz86xzLRp06RmzZpSqlQpSU1NlY0bN4a6aQAAAAAiJbE4d+6cNGrUyCQCwdi7d6907txZ2rZtK9u2bZMhQ4bIgw8+KEuWLPEsM3/+fBk6dKiMHj1atmzZYtbfoUMHOXbsWKibBwAAACAM4kJ9QadOncwUrOnTp0utWrXk5ZdfNo9vvPFGWbNmjbzyyismeVCTJk2SAQMGSL9+/Tyv+eyzz2TWrFny5JNPhrqJAAAAAIp6YhGqdevWSXp6us88TSi05kJdvHhRNm/eLCNGjPA8X6JECfMafW0gFy5cMJMtIyPD/M3KyjJTtLL3PZpj4Abi6g7i6h5i6w7iGplxjZNsiSSFFQfKqzuiMa5ZIeyr64nFkSNHpGrVqj7z9LEmA7/++qv88ssvcvny5YDL7NixI+A6x48fL2PHjs0xf+nSpZKYmCjRbtmyZeHehGKJuLqDuLqH2LqDuEZWXH9XUSLKokWLCnV9lFd3RFNcMzMzi05i4Qat3dA+GTZNUlJSUqR9+/ZSrly5sG7b4Pe3uLLeqfc3DSqj1ILerl07iY+Pl+IoHPGNhriGA3F179zQO7TtKx6Tpb9UkUsOB/8L5rMnWj4jIq3MhvP7KBRux9WtOLilsOIbaeU1UuQV18ERcs6Fym4ZVCQSi6SkJDl69KjPPH2sCUDp0qUlNjbWTIGW0dcGoqNL6eRPD3C4Tx6nX+K5CWW/ikIcimN8i3Ncw4m4undu6Dyn50ykHZsr8RkRKWW2KHwfhbpeN9btVhzcUtgxiJTyGmkCxfVShJ1zbry/62dbWlqarFixwmeeZno6X5UsWVKaNWvms0x2drZ5bC8DAAAAoGgLObE4e/asGTZWJ3s4Wf3//v37Pc2Uevfu7Vn+D3/4g/zwww8yfPhw02fi9ddflw8//FAee+wxzzLarGnGjBny7rvvyvbt22XQoEFmWFt7lCgAAAAARVvITaE2bdpkfpPCZvd16NOnj/nhu8OHD3uSDKVDzerQsZpITJkyRa655hqZOXOmZ6hZ1b17dzl+/LiMGjXKdPZu3LixLF68OEeHbgAAAADFJLFo06aNWJaV6/OBflVbX7N169Y81zt48GAzAQAAAIg8kdWjCQAAAECRRGIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAADhSSymTZsmNWvWlFKlSklqaqps3Lgx12XbtGkjMTExOabOnTt7lunbt2+O5zt27FiwPQIAAABwxcWF+oL58+fL0KFDZfr06SapmDx5snTo0EF27twpVapUybH8xx9/LBcvXvQ8PnnypDRq1Ejuvfden+U0kXjnnXc8jxMSEkLfGwAAAACRUWMxadIkGTBggPTr10/q169vEozExESZNWtWwOUrVaokSUlJnmnZsmVmef/EQhMJ7+UqVqxY8L0CAAAAUHQTC6152Lx5s6Snp/97BSVKmMfr1q0Lah1vv/229OjRQ8qUKeMzf+XKlabGo27dujJo0CBTswEAAACgGDaFOnHihFy+fFmqVq3qM18f79ixI9/Xa1+Mb7/91iQX/s2g7r77bqlVq5bs2bNHnnrqKenUqZNJVmJjY3Os58KFC2ayZWRkmL9ZWVlmCqc4yXZlvcHsl71MuGNQ3OIbDXENB+Lq3rlh/78wzpdIOz5ufkZEWpkN5/dRQdbnVlzdioNbCisOkVZeI0VecY2LkHPOzfePsSzLCnbhQ4cOSfXq1WXt2rWSlpbmmT98+HBZtWqVbNiwIc/XP/TQQyZZ+Prrr/Nc7ocffpDrr79eli9fLnfccUeO58eMGSNjx47NMX/u3LmmmRUAAAAA5zIzM6VXr15y+vRpKVeuXOHVWFSuXNnUIBw9etRnvj7WfhF5OXfunMybN0+eeeaZfN/nuuuuM++1e/fugInFiBEjTAdy7xqLlJQUad++fb477LbB729xZb1T728aVEapfVjatWsn8fHxUhyFI77RENdwIK7unRt616x9xWOy9JcqcsnhqOLBfPZEy2dEpJXZcH4fhcLtuLoVB7cUVnwjrbxGirziOjhCzrlQ2S2DghFSYlGyZElp1qyZrFixQrp162bmZWdnm8eDBw/O87ULFiwwzZd+//vf5/s+Bw4cMH0sqlWrFvB57egdaNQoPcDhPnmcfonnJpT9KgpxKI7xLc5xDSfi6t65ofOcnjORdmyuxGdEpJTZovB9FOp63Vi3W3FwS2HHIFLKa6QJFNdLEXbOufH+IUdAawpmzJgh7777rmzfvt10tNbaCB0lSvXu3dvUKPjTfhWajFx11VU+88+ePSvDhg2T9evXy759+0yS0rVrV6ldu7YZxhYAAABAMfwdi+7du8vx48dl1KhRcuTIEWncuLEsXrzY06F7//79ZqQob/obF2vWrJGlS5fmWJ82rdI+F5qonDp1SpKTk02TpnHjxvFbFgAAAEBxTSyUNnvKremTDhvrT4eQza2PeOnSpWXJkiUF2QwAAAAARURkNTwEAAAAUCSRWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAADCk1hMmzZNatasKaVKlZLU1FTZuHFjrsvOnj1bYmJifCZ9nTfLsmTUqFFSrVo1KV26tKSnp8uuXbsKsmkAAAAAIiGxmD9/vgwdOlRGjx4tW7ZskUaNGkmHDh3k2LFjub6mXLlycvjwYc/0448/+jw/YcIEefXVV2X69OmyYcMGKVOmjFnn+fPnC7ZXAAAAAIp2YjFp0iQZMGCA9OvXT+rXr2+SgcTERJk1a1aur9FaiqSkJM9UtWpVn9qKyZMny9NPPy1du3aVhg0bypw5c+TQoUOycOHCgu8ZAAAAgCsmLpSFL168KJs3b5YRI0Z45pUoUcI0XVq3bl2urzt79qzUqFFDsrOzpWnTpvL8889LgwYNzHN79+6VI0eOmHXYypcvb5pY6Tp79OiRY30XLlwwky0jI8P8zcrKMlM4xUm2K+sNZr/sZcIdg+IW32iIazgQV/fODfv/hXG+RNrxcfMzItLKbDi/jwqyPrfi6lYc3FJYcYi08hop8oprXIScc26+f4ylVQZB0lqE6tWry9q1ayUtLc0zf/jw4bJq1SrTjMmfJgfaX0JrIk6fPi0TJ06U1atXy3fffSfXXHONWdett95q1q19LGz33XefqenQplf+xowZI2PHjs0xf+7cuab2BAAAAIBzmZmZ0qtXL3Mdr90bCq3GoiA0AfFOQlq2bCk33nijvPnmmzJu3LgCrVNrTLSfh3eNRUpKirRv3z7fHXbb4Pe3uLLeqfc3DSqjXLZsmbRr107i4+OlOApHfKMhruFAXN07N/SuWfuKx2TpL1XkksPB/4L57ImWz4hIK7Ph/D4KhdtxdSsObims+EZaeY0UecV1cIScc6GyWwYFI6TEonLlyhIbGytHjx71ma+Pte9EMPQgNGnSRHbv3m0e26/TdXjXWOjjxo0bB1xHQkKCmQKtO9wnj9Mv8dyEsl9FIQ7FMb7FOa7hRFzdOzd0ntNzJtKOzZX4jIiUMlsUvo9CXa8b63YrDm4p7BhESnmNNIHieinCzjk33j+kCJQsWVKaNWsmK1as8MzTfhP62LtWIi+XL1+Wb775xpNE1KpVyyQX3uvUzEibVQW7TgAAAADhFXJTKG2C1KdPH2nevLm0aNHCjOh07tw5M0qU6t27t+mHMX78ePP4mWeekVtuuUVq164tp06dkpdeeskMN/vggw+a57UfxZAhQ+TZZ5+VOnXqmERj5MiRkpycLN26dSvs/QUAAABQFBKL7t27y/Hjx80P2uloTtpcafHixZ4hZPfv329GirL98ssvZnhaXbZixYqmxkM7bOtQtd6dvzU5GThwoEk+WrVqZdbp/0N6AAAAAIqmAnXeHjx4sJkCWblypc/jV155xUx50VoLrdnQCQAAAEDkiaweTQAAAACKJBILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAAAIT2Ixbdo0qVmzppQqVUpSU1Nl48aNuS47Y8YMue2226RixYpmSk9Pz7F83759JSYmxmfq2LFjQTYNAAAAQCQkFvPnz5ehQ4fK6NGjZcuWLdKoUSPp0KGDHDt2LODyK1eulJ49e8oXX3wh69atk5SUFGnfvr0cPHjQZzlNJA4fPuyZPvjgg4LvFQAAAICinVhMmjRJBgwYIP369ZP69evL9OnTJTExUWbNmhVw+ffff18efvhhady4sdSrV09mzpwp2dnZsmLFCp/lEhISJCkpyTNp7QYAAACAYphYXLx4UTZv3myaM3lWUKKEeay1EcHIzMyUrKwsqVSpUo6ajSpVqkjdunVl0KBBcvLkyVA2DQAAAEAYxYWy8IkTJ+Ty5ctStWpVn/n6eMeOHUGt409/+pMkJyf7JCfaDOruu++WWrVqyZ49e+Spp56STp06mWQlNjY2xzouXLhgJltGRob5qwmLTuEUJ9murDeY/bKXCXcMilt8oyGu4UBc3Ts37P8XxvkSacfHzc+ISCuz4fw+Ksj63IqrW3FwS2HFIdLKa6TIK65xEXLOufn+MZZlWcEufOjQIalevbqsXbtW0tLSPPOHDx8uq1atkg0bNuT5+hdeeEEmTJhgaicaNmyY63I//PCDXH/99bJ8+XK54447cjw/ZswYGTt2bI75c+fONc2yAAAAADinrY169eolp0+flnLlyhVejUXlypVNDcLRo0d95utj7ReRl4kTJ5rEQpOFvJIKdd1115n32r17d8DEYsSIEaYDuXeNhd0pPL8ddtvg97e4st6p9zcNKqNctmyZtGvXTuLj46U4Ckd8oyGu4UBc3Ts39K5Z+4rHZOkvVeSSw1HFg/nsiZbPiEgrs+H8PgqF23F1Kw5uKaz4Rlp5jRR5xXVwhJxzobJbBgUjpMSiZMmS0qxZM9Pxulu3bmae3RF78ODBub5Oaymee+45WbJkiTRv3jzf9zlw4IDpY1GtWrWAz2tHb5386QEO98nj9Es8N6HsV1GIQ3GMb3GOazgRV/fODZ3n9JyJtGNzJT4jIqXMFoXvo1DX68a63YqDWwo7BpFSXiNNoLheirBzzo33DzkCWlOgv03x7rvvyvbt201H63PnzplRolTv3r1NjYLtxRdflJEjR5pRo/S3L44cOWKms2fPmuf177Bhw2T9+vWyb98+k6R07dpVateubYaxBQAAAFD0hVRjobp37y7Hjx+XUaNGmQRBh5FdvHixp0P3/v37zUhRtjfeeMOMJnXPPff4rEd/B0P7SmjTqq+//tokKqdOnTIdu7VJ07hx4wLWSgAAAAAoBomF0mZPuTV90o7Z3rQWIi+lS5c2TaQAAAAARK7IangIAAAAoEgisQAAAADgGIkFAAAAAMdILAAAAAA4RmIBAAAAwDESCwAAAACOkVgAAAAAcIzEAgAAAIBjJBYAAAAAHCOxAAAAAOAYiQUAAAAAx0gsAAAAADhGYgEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAYyQWAAAAABwjsQAAAADgGIkFAAAAAMdILAAAAACEJ7GYNm2a1KxZU0qVKiWpqamycePGPJdfsGCB1KtXzyx/8803y6JFi3yetyxLRo0aJdWqVZPSpUtLenq67Nq1qyCbBgAAACASEov58+fL0KFDZfTo0bJlyxZp1KiRdOjQQY4dOxZw+bVr10rPnj2lf//+snXrVunWrZuZvv32W88yEyZMkFdffVWmT58uGzZskDJlyph1nj9/3tneAQAAACiaicWkSZNkwIAB0q9fP6lfv75JBhITE2XWrFkBl58yZYp07NhRhg0bJjfeeKOMGzdOmjZtKlOnTvXUVkyePFmefvpp6dq1qzRs2FDmzJkjhw4dkoULFzrfQwAAAACuiwtl4YsXL8rmzZtlxIgRnnklSpQwTZfWrVsX8DU6X2s4vGlthJ007N27V44cOWLWYStfvrxpYqWv7dGjR451XrhwwUy206dPm78///yzZGVlSThl/3rGlfWePHky32V03zMzM82y8fHxUhyFI77RENdwIK7unRvZki2ZCZlmXrbDrnTBfPZEy2dEpJXZcH4fhcLtuLoVB7cUVnwjrbxGirzimh0h51yozpw546kMKNTE4sSJE3L58mWpWrWqz3x9vGPHjoCv0aQh0PI6337enpfbMv7Gjx8vY8eOzTG/Vq1aUlzNfjjcW1C8EV8UNzMLaT2cG/8/4vBvxMJdxBdFtUxogqE3/wstsSgqtMbEuxYkOzvb1FZcddVVEhMTI9EqIyNDUlJS5KeffpJy5cqFe3OKDeLqDuLqHmLrDuLqDuLqDuLqjmiMq2VZJqlITk7Od9mQEovKlStLbGysHD161Ge+Pk5KSgr4Gp2f1/L2X52no0J5L9O4ceOA60xISDCTtwoVKoSyK8WaFvRoKexXEnF1B3F1D7F1B3F1B3F1B3F1R7TFtXw+NRW2kBrflixZUpo1ayYrVqzwqS3Qx2lpaQFfo/O9l1fLli3zLK/NlzS58F5Gs0EdHSq3dQIAAAAoWkJuCqVNkPr06SPNmzeXFi1amBGdzp07Z0aJUr1795bq1aubfhDq0UcfldatW8vLL78snTt3lnnz5smmTZvkrbfeMs9r06UhQ4bIs88+K3Xq1DGJxsiRI011iw5LCwAAAKAYJhbdu3eX48ePmx+0087V2lxp8eLFns7X+/fvNyNF2Vq2bClz5841w8k+9dRTJnnQEaFuuukmzzLDhw83ycnAgQPl1KlT0qpVK7NO/UE9BE+bh+nvi/g3E4MzxNUdxNU9xNYdxNUdxNUdxNUdxDVvMVYwY0cBAAAAQB6cDXAOAAAAACQWAAAAAAoDiQUAAAAAx0gsAAAAADhGYlHETZs2TWrWrGlGyEpNTZWNGzfmuuyMGTPktttuk4oVK5opPT09x/LaV19H9NIfIyxdurRZZteuXRJtCjuuffv2NUMne08dO3aUaBNKXD/++GMzbLX+uGWZMmXMCHPvvfeezzKUV3fiSnkNPa7edNh0jZn/kOiUV/diS5kNPa6zZ8/OETP/0TYps+7EtW80l1cdFQpF07x586ySJUtas2bNsr777jtrwIABVoUKFayjR48GXL5Xr17WtGnTrK1bt1rbt2+3+vbta5UvX946cOCAZ5kXXnjBzFu4cKH11VdfWXfeeadVq1Yt69dff7WihRtx7dOnj9WxY0fr8OHDnunnn3+2okmocf3iiy+sjz/+2Pr++++t3bt3W5MnT7ZiY2OtxYsXe5ahvLoTV8pr6HG17d2716pevbp12223WV27dvV5jvLqXmwps6HH9Z133rHKlSvnE7MjR474LEOZdSeufaK4vJJYFGEtWrSwHnnkEc/jy5cvW8nJydb48eODev2lS5essmXLWu+++655nJ2dbSUlJVkvvfSSZ5lTp05ZCQkJ1gcffGBFi8KOq/0h4v9FGG2cxlU1adLEevrpp83/Ka/uxFVRXgsWVz33W7Zsac2cOTNHDCmv7sVWUWZDj6teAGvSkBvKrDtxjfbySlOoIurixYuyefNmUy1p0x8e1Mfr1q0Lah2ZmZmSlZUllSpVMo/37t1rftTQe53ly5c31X7BrjPSuRFX28qVK6VKlSpSt25dGTRokJw8eVKihdO46k2OFStWyM6dO+X222838yiv7sTVRnkNPa7PPPOMiVn//v1zPEd5dS+2Nsps6HE9e/as1KhRQ1JSUqRr167y3XffeZ6jzLoT12gvryH/8jaujBMnTsjly5c9v2hu08c7duwIah1/+tOfJDk52XPC6AeIvQ7/ddrPFXduxFVp28m7775batWqJXv27DG/Mt+pUyfzwRQbGyvFXUHjevr0aalevbpcuHDBxOn111+Xdu3amecor+7EVVFeQ4/rmjVr5O2335Zt27YFfJ7y6l5sFWU29LjqBe2sWbOkYcOG5jNh4sSJ0rJlS3MRfM0111BmXYprtJdXEoti6oUXXjCd4DRj9u9UhMKPa48ePTz/v/nmm80HzvXXX2+Wu+OOO8K0tUVf2bJlzcWE3v3RO+tDhw6V6667Ttq0aRPuTSvWcaW8hubMmTPywAMPmIEcKleuHO7NicrYUmZDl5aWZiabXvzeeOON8uabb8q4cePCum3FPa49ori8klgUUfoBq1nt0aNHfebr46SkpDxfq9mzXgAvX77cFGab/Tpdh44A4b1OHTkmGrgR10D0Ik7fa/fu3cX+Q8RJXLXKuXbt2ub/Wga3b98u48ePNxfAlFd34hoI5TXvuOodx3379kmXLl0887Kzs83fuLg409SM8upebPWCzB9lNvjvLlt8fLw0adLExExRZt2JayDRVF7pY1FElSxZUpo1a2buNnp/2Opj70zZ34QJE0zGvHjxYjPkpDetktMTxXudGRkZsmHDhjzXWZy4EddADhw4YNpTen9YF2cFjas/fY0231GUV3fiGgjlNe+41qtXT7755htTC2RPd955p7Rt29b8X9tZU17di20glNnQPwu0yY/G2o4ZZdaduEq0l9dw9x5H3kOg6egMs2fPNkNHDhw40AyBZg9r9sADD1hPPvmkz7BxOmTaRx995DPE2ZkzZ3yW0XV8+umn1tdff21GLYjGoeUKM67694knnrDWrVtnhktcvny51bRpU6tOnTrW+fPnrWgRalyff/55a+nSpdaePXvM8hMnTrTi4uKsGTNmeJahvBZ+XCmvBYtrMKO+UF7diS1ltmBxHTt2rLVkyRLzWbB582arR48eVqlSpcyQqjbKbOHH9UyUl1cSiyLutddes6699lpzYatDoq1fv97zXOvWrc0HsK1GjRqW5or+0+jRo32Glxs5cqRVtWpVcyLdcccd1s6dO61oU5hxzczMtNq3b29dffXVVnx8vFlex8H2H9c6GoQS1z//+c9W7dq1zQdyxYoVrbS0NPMB743yWvhxpbwWLK7BJBaUV3diS5ktWFyHDBniWVbL5O9+9ztry5YtPuujzBZ+XDOjvLzG6D/hrjUBAAAAENnoYwEAAADAMRILAAAAAI6RWAAAAABwjMQCAAAAgGMkFgAAAAAcI7EAAAAA4BiJBQAAAADHSCwAAAAAOEZiAQAAAMAxEgsAAAAAjpFYAAAAAHCMxAIAAACAOPX/AXXxRqFx0YLVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sentiment_df['p_positive_wmean'].hist(bins=30, alpha=0.7, ax=ax)\n",
    "ax.set_title('Distribution of weighted positive probabilities')\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
